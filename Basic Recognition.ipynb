{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the train images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImg=face_recognition.load_image_file('train images/MS-Dhoni.jpg')\n",
    "\n",
    "#covert BGR Images to RGB using cv2\n",
    "trainImg=cv2.cvtColor(trainImg,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "testImg=face_recognition.load_image_file('train images/test_dhoni.jpg')\n",
    "testImg=cv2.cvtColor(testImg,cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 246, 122, 183)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[126, 135, 155],\n",
       "        [127, 136, 156],\n",
       "        [127, 136, 156],\n",
       "        ...,\n",
       "        [ 92,  99, 118],\n",
       "        [ 91,  97, 116],\n",
       "        [ 90,  96, 115]],\n",
       "\n",
       "       [[127, 136, 156],\n",
       "        [127, 136, 156],\n",
       "        [128, 137, 157],\n",
       "        ...,\n",
       "        [ 92,  99, 118],\n",
       "        [ 92,  98, 117],\n",
       "        [ 90,  96, 115]],\n",
       "\n",
       "       [[127, 136, 156],\n",
       "        [128, 137, 157],\n",
       "        [128, 137, 157],\n",
       "        ...,\n",
       "        [ 93, 100, 119],\n",
       "        [ 92,  98, 117],\n",
       "        [ 90,  96, 115]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[140, 167, 188],\n",
       "        [140, 167, 188],\n",
       "        [140, 166, 190],\n",
       "        ...,\n",
       "        [129, 154, 174],\n",
       "        [130, 155, 175],\n",
       "        [131, 156, 176]],\n",
       "\n",
       "       [[138, 165, 186],\n",
       "        [137, 163, 187],\n",
       "        [137, 163, 187],\n",
       "        ...,\n",
       "        [129, 153, 173],\n",
       "        [130, 154, 174],\n",
       "        [131, 155, 175]],\n",
       "\n",
       "       [[132, 160, 184],\n",
       "        [130, 158, 182],\n",
       "        [130, 155, 181],\n",
       "        ...,\n",
       "        [134, 158, 178],\n",
       "        [134, 158, 178],\n",
       "        [133, 157, 177]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lOCATING THE FACE AND DETECTION\n",
    "\n",
    "faceLoc=face_recognition.face_locations(trainImg)[0]\n",
    "encode=face_recognition.face_encodings(trainImg)[0]\n",
    "\n",
    "#gives the size of the rectangle of face located\n",
    "print(faceLoc);\n",
    "\n",
    "cv2.rectangle(trainImg,(faceLoc[3],faceLoc[0]),(faceLoc[1],faceLoc[2]),(255,0,255),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 69,  80,  94],\n",
       "        [ 70,  82,  94],\n",
       "        [ 71,  83,  95],\n",
       "        ...,\n",
       "        [110, 141, 126],\n",
       "        [112, 144, 127],\n",
       "        [110, 144, 127]],\n",
       "\n",
       "       [[ 69,  80,  94],\n",
       "        [ 69,  81,  93],\n",
       "        [ 70,  82,  94],\n",
       "        ...,\n",
       "        [116, 147, 132],\n",
       "        [117, 149, 132],\n",
       "        [116, 150, 133]],\n",
       "\n",
       "       [[ 68,  80,  92],\n",
       "        [ 68,  80,  92],\n",
       "        [ 69,  81,  93],\n",
       "        ...,\n",
       "        [118, 149, 134],\n",
       "        [117, 151, 134],\n",
       "        [118, 152, 135]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 92, 183, 168],\n",
       "        [ 93, 184, 169],\n",
       "        [ 95, 186, 171],\n",
       "        ...,\n",
       "        [ 88, 186, 180],\n",
       "        [ 88, 186, 180],\n",
       "        [ 86, 186, 180]],\n",
       "\n",
       "       [[ 88, 182, 165],\n",
       "        [ 90, 184, 167],\n",
       "        [ 92, 187, 167],\n",
       "        ...,\n",
       "        [ 92, 186, 181],\n",
       "        [ 92, 186, 181],\n",
       "        [ 92, 186, 181]],\n",
       "\n",
       "       [[ 89, 183, 166],\n",
       "        [ 91, 185, 168],\n",
       "        [ 93, 188, 168],\n",
       "        ...,\n",
       "        [ 92, 186, 181],\n",
       "        [ 92, 186, 181],\n",
       "        [ 92, 186, 181]]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLocTest=face_recognition.face_locations(testImg)[0]\n",
    "encodeTest=face_recognition.face_encodings(testImg)[0]\n",
    "cv2.rectangle(testImg,(faceLocTest[3],faceLocTest[0]),(faceLocTest[1],faceLocTest[2]),(255,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "#Here we compare alist of images with the test \n",
    "#image with the encode values \n",
    "#Return True if matches or False\n",
    "\n",
    "result=face_recognition.compare_faces([encode],encodeTest)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 324, 325, 139)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [176, 182, 181],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       [[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       [[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26,  18,  18],\n",
       "        [ 24,  16,  16],\n",
       "        [ 24,  17,  14],\n",
       "        ...,\n",
       "        [ 33,  21,  21],\n",
       "        [ 35,  23,  21],\n",
       "        [ 39,  26,  24]],\n",
       "\n",
       "       [[ 28,  18,  18],\n",
       "        [ 27,  17,  17],\n",
       "        [ 28,  18,  18],\n",
       "        ...,\n",
       "        [ 31,  19,  19],\n",
       "        [ 34,  22,  22],\n",
       "        [ 36,  23,  21]],\n",
       "\n",
       "       [[ 32,  22,  22],\n",
       "        [ 30,  20,  20],\n",
       "        [ 31,  21,  21],\n",
       "        ...,\n",
       "        [ 30,  18,  18],\n",
       "        [ 34,  22,  22],\n",
       "        [ 35,  23,  23]]], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare another image with train image\n",
    "\n",
    "testImg2=face_recognition.load_image_file('train images/Elon_Musk.jpg')\n",
    "testImg2=cv2.cvtColor(testImg2,cv2.COLOR_BGR2RGB)\n",
    "testFaceLoc=face_recognition.face_locations(testImg2)[0]\n",
    "testEncode2=face_recognition.face_encodings(testImg2)[0]\n",
    "print(testFaceLoc)\n",
    "\n",
    "cv2.rectangle(testImg2,(testFaceLoc[3],testFaceLoc[0]),(testFaceLoc[1],testFaceLoc[2]),(255,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "result2=face_recognition.compare_faces([encode],testEncode2)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True] [0.42635705]\n"
     ]
    }
   ],
   "source": [
    "#Face Distance calculations\n",
    "\n",
    "faceDis=face_recognition.face_distance([encode],encodeTest)\n",
    "\n",
    "#True : Compare two same faces\n",
    "print(result,faceDis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False] [0.7841771]\n"
     ]
    }
   ],
   "source": [
    "#False: Compare two different faces\n",
    "faceDis2=face_recognition.face_distance([encode],testEncode2)\n",
    "print(result2,faceDis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [176, 182, 181],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       [[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       [[184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        [184, 189, 188],\n",
       "        ...,\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180],\n",
       "        [175, 181, 180]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26,  18,  18],\n",
       "        [ 24,  16,  16],\n",
       "        [ 24,  17,  14],\n",
       "        ...,\n",
       "        [ 33,  21,  21],\n",
       "        [ 35,  23,  21],\n",
       "        [ 39,  26,  24]],\n",
       "\n",
       "       [[ 28,  18,  18],\n",
       "        [ 27,  17,  17],\n",
       "        [ 28,  18,  18],\n",
       "        ...,\n",
       "        [ 31,  19,  19],\n",
       "        [ 34,  22,  22],\n",
       "        [ 36,  23,  21]],\n",
       "\n",
       "       [[ 32,  22,  22],\n",
       "        [ 30,  20,  20],\n",
       "        [ 31,  21,  21],\n",
       "        ...,\n",
       "        [ 30,  18,  18],\n",
       "        [ 34,  22,  22],\n",
       "        [ 35,  23,  23]]], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print The Values in the Images\n",
    "cv2.putText(trainImg,'Train Source Image',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "\n",
    "#TestImages\n",
    "cv2.putText(testImg,f'{result} {faceDis}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "cv2.putText(testImg2,f'{result2} {faceDis2}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Dhoni',trainImg)\n",
    "cv2.imshow('test Dhoni',testImg)\n",
    "cv2.imshow('Elon Musk',testImg2)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
